{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "676a1b35-5db7-4360-89cf-b0afb1716e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c25ff431-f53a-4a77-be0a-1c1519854edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/gnews-swivel/TensorFlow2/tf2-preview-20dim/1\", output_shape=[],\n",
    "                           input_shape=[], dtype=tf.string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0992aa81-1376-4f92-a83e-62b4c3d08723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was an absolutely terrible movie. Don't b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been known to fall asleep during films,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mann photographs the Alberta Rocky Mountains i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the kind of film for a snowy Sunday af...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As others have mentioned, all the women that g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  This was an absolutely terrible movie. Don't b...      0\n",
       "1  I have been known to fall asleep during films,...      0\n",
       "2  Mann photographs the Alberta Rocky Mountains i...      0\n",
       "3  This is the kind of film for a snowy Sunday af...      1\n",
       "4  As others have mentioned, all the women that g...      1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "valid = pd.read_csv('validation.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "94dd401a-1303-47a6-a28e-a623689ac1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            object\n",
       "label            int64\n",
       "preproc_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "751a7e26-32cc-4842-9ac2-ce347f4245cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preproc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was an absolutely terrible movie. Don't b...</td>\n",
       "      <td>0</td>\n",
       "      <td>this was an absolutely terrible movie  don t b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been known to fall asleep during films,...</td>\n",
       "      <td>0</td>\n",
       "      <td>i have been known to fall asleep during films ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mann photographs the Alberta Rocky Mountains i...</td>\n",
       "      <td>0</td>\n",
       "      <td>mann photographs the alberta rocky mountains i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the kind of film for a snowy Sunday af...</td>\n",
       "      <td>1</td>\n",
       "      <td>this is the kind of film for a snowy sunday af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As others have mentioned, all the women that g...</td>\n",
       "      <td>1</td>\n",
       "      <td>as others have mentioned  all the women that g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  This was an absolutely terrible movie. Don't b...      0   \n",
       "1  I have been known to fall asleep during films,...      0   \n",
       "2  Mann photographs the Alberta Rocky Mountains i...      0   \n",
       "3  This is the kind of film for a snowy Sunday af...      1   \n",
       "4  As others have mentioned, all the women that g...      1   \n",
       "\n",
       "                                        preproc_text  \n",
       "0  this was an absolutely terrible movie  don t b...  \n",
       "1  i have been known to fall asleep during films ...  \n",
       "2  mann photographs the alberta rocky mountains i...  \n",
       "3  this is the kind of film for a snowy sunday af...  \n",
       "4  as others have mentioned  all the women that g...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"<br />\", \" \")\n",
    "    text = ''.join([c if c.isalpha() or c.isspace() else ' ' for c in text])\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "train['preproc_text'] = train['text'].apply(preprocess_text)\n",
    "test['preproc_text'] = test['text'].apply(preprocess_text)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6501c6db-61b7-4ddf-a578-6df65594c280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        this was an absolutely terrible movie  don t b...\n",
       "1        i have been known to fall asleep during films ...\n",
       "2        mann photographs the alberta rocky mountains i...\n",
       "3        this is the kind of film for a snowy sunday af...\n",
       "4        as others have mentioned  all the women that g...\n",
       "                               ...                        \n",
       "14995    i saw this movie in       i was    or     when...\n",
       "14996    the only reason i give this movie an   out of ...\n",
       "14997    i saw this movie in my childhood  and after   ...\n",
       "14998    could contain spoilers     i m surprised by th...\n",
       "14999    long  boring  blasphemous  never have i been s...\n",
       "Name: preproc_text, Length: 15000, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.preproc_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9084fa11-4a62-4d89-8bdb-0f6e90c809d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       "array([  11,   14,   35,  443,  373,   17,   88,   22,   29, 9059,    9,\n",
       "         34, 1288, 3495,   41,  498,    1,  198,   27,   84,  157,   19,\n",
       "         11,  206,  329,   29,   68,  245,  218,    9,  470,   60,   68,\n",
       "         84,  114,   97,   24, 6098,   11,   17,   13,  664,  758,   11,\n",
       "         17,    7,   35,  402, 7601,  179, 2363,  414,    2,   90, 1148,\n",
       "        136,   71,  147,   54,    2,    1, 7577,   71,  228,   68, 3022,\n",
       "         16,    1, 2551,    1,    1, 1468, 4505,    3,   42, 3950,  116,\n",
       "       1680,   18, 3495,   14,  161,   19,    4, 1148,  879, 7408,    9,\n",
       "          4,   17,   12,   14, 3912,    5,  100,  146, 1115,   10,  230,\n",
       "        665])>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = 10000\n",
    "max_length = 100\n",
    "\n",
    "# Create the TextVectorization layer\n",
    "vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=max_length, pad_to_max_tokens=True)\n",
    "\n",
    "# Adapt the vectorizer to the training data\n",
    "vectorizer.adapt(train['preproc_text'])\n",
    "vectorizer(train['preproc_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6817352b-b3fa-4ebe-a75a-25098a85625f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=float32, numpy=\n",
       "array([[ 1.765786  , -3.882232  ,  3.9134233 , -1.5557289 , -3.3362343 ,\n",
       "        -1.7357955 , -1.9954445 ,  1.2989551 ,  5.081598  , -1.1041286 ,\n",
       "        -2.0503852 , -0.72675157, -0.65675956,  0.24436149, -3.7208383 ,\n",
       "         2.0954835 ,  2.2969332 , -2.0689783 , -2.9489717 , -1.1315987 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = tf.constant([(train.iloc[0]['text'])])\n",
    "hub_layer(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d3350805-3f90-4c2a-8154-93b442a3e916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#old\n",
    "model = tf.keras.models.Sequential([\n",
    "  hub_layer,\n",
    "  keras.layers.Reshape((20, 1)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(40, return_sequences=True)),\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "  tf.keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13f15a-a0d5-468b-919c-de70a4097024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "model = tf.keras.models.Sequential([\n",
    "  hub_layer,\n",
    "  tf.keras.layers.Dense(1000, activation='relu'),\n",
    "  tf.keras.layers.Dense(500, activation='relu'),\n",
    "  tf.keras.layers.Dense(250, activation='relu'),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f071aca4-0272-4eb1-bcc6-87df658f2e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_5 (TextV  (None, 100)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_16 (Embedding)    (None, 100, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional_55 (Bidirecti  (None, 100, 40)          5920      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_56 (Bidirecti  (None, 40)               9760      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 6)                 246       \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,933\n",
      "Trainable params: 175,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#current\n",
    "model = tf.keras.models.Sequential([\n",
    "   # keras.layers.Reshape(None,),\n",
    "    tf.keras.layers.InputLayer(input_shape=[1], dtype=\"string\"),\n",
    "    vectorizer,\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=16, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    #tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1eebfde5-8f0c-4928-aa39-f6d295d21248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#type(train['preproc_text'].iloc[0])\n",
    "train[\"preproc_text\"] = train.preproc_text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ce3fd53d-45ac-4f77-867c-f431119ce8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size= 100\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train[\"preproc_text\"], train[\"label\"]))\n",
    "train_ds = train_ds.shuffle(buffer_size=len(train[\"preproc_text\"])).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cdab77-59ce-43d6-972b-8211606ded0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "150/150 [==============================] - 28s 136ms/step - loss: 0.6129 - accuracy: 0.4993\n",
      "Epoch 2/6\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 0.3635 - accuracy: 0.4993\n",
      "Epoch 3/6\n",
      "150/150 [==============================] - 20s 134ms/step - loss: 0.2509 - accuracy: 0.4993\n",
      "Epoch 4/6\n",
      "150/150 [==============================] - 20s 135ms/step - loss: 0.1968 - accuracy: 0.4993\n",
      "Epoch 5/6\n",
      "150/150 [==============================] - 22s 144ms/step - loss: 0.1504 - accuracy: 0.4993\n",
      "Epoch 6/6\n",
      "112/150 [=====================>........] - ETA: 5s - loss: 0.1092 - accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, epochs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6105bdd-70cf-43df-aa7c-0f4dca5dbc97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 11ms/step - loss: 0.5766 - sparse_categorical_accuracy: 0.5000\n",
      "\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test['text'], test['label'])\n",
    "print('\\nTest accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95cc9f9b-8cf1-471f-8d2f-d3a612b5937e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       ...,\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4e87f9-2baa-42da-b6a7-321f984c6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_v1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d516ed65-53e2-4e54-9569-5b9dadd7fdd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model_v1/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://model_v1/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://model_v1/fingerprint.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://model_v1/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "- [4 files][  1.7 MiB/  1.7 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://model_v1/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://model_v1/assets/tokens.txt [Content-Type=text/plain]...          \n",
      "- [6 files][  1.8 MiB/  1.8 MiB]                                                \n",
      "Operation completed over 6 objects/1.8 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'reddit_raw_data_0184598608709384596' # use your own bucket name here\n",
    "!gsutil cp -r model_v1 gs://{BUCKET}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12533e67-48db-48db-995c-97606dec3113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://train.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 19.0 MiB/ 19.0 MiB]                                                \n",
      "Operation completed over 1 objects/19.0 MiB.                                     \n",
      "Copying file://validation.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 12.8 MiB/ 12.8 MiB]                                                \n",
      "Operation completed over 1 objects/12.8 MiB.                                     \n",
      "Copying file://test.csv [Content-Type=text/csv]...\n",
      "- [1 files][ 31.1 MiB/ 31.1 MiB]                                                \n",
      "Operation completed over 1 objects/31.1 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "def to_csv(data, filename):\n",
    "  \"\"\"Takes TF Dataset and writes it to a (local) CSV file. Make sure the dataset is not too large!\"\"\"\n",
    "  import csv\n",
    "\n",
    "  data_list = [{ 'text': text.decode('utf-8'), 'label': label } for text, label in data.as_numpy_iterator()]\n",
    "  filename = '{}.csv'.format(filename)\n",
    "\n",
    "  with open(filename, 'w') as f:\n",
    "    writer = csv.DictWriter(f, data_list[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data_list)\n",
    "\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n",
    "\n",
    "to_csv(train_data, 'train')\n",
    "to_csv(validation_data, 'validation')\n",
    "to_csv(test_data, 'test')\n",
    "\n",
    "BUCKET = 'reddit_raw_data_0184598608709384596' # use your own bucket name here\n",
    "!gsutil cp train.csv gs://{BUCKET}/\n",
    "!gsutil cp validation.csv gs://{BUCKET}/\n",
    "!gsutil cp test.csv gs://{BUCKET}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9b94bb6-4291-4ad4-8f85-9cca37b630ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was an absolutely terrible movie. Don't b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have been known to fall asleep during films,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mann photographs the Alberta Rocky Mountains i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the kind of film for a snowy Sunday af...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As others have mentioned, all the women that g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  This was an absolutely terrible movie. Don't b...      0\n",
       "1  I have been known to fall asleep during films,...      0\n",
       "2  Mann photographs the Alberta Rocky Mountains i...      0\n",
       "3  This is the kind of film for a snowy Sunday af...      1\n",
       "4  As others have mentioned, all the women that g...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fda4c2-cc10-4905-b4ec-b0116129652b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3640b90-5c69-4255-9f19-1aec1e69baf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1025, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 989, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/tmp/__autograph_generated_filebiwe9zve.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1025, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 989, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f021385-4d78-48ca-ad8f-585c5d515ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
